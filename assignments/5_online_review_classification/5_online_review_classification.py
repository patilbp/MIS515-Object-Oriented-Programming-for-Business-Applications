# -*- coding: utf-8 -*-
"""Homework 5_Bhagyashri Patil

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12adEaFfY9CDPLZoG-Lz2e9RWdFtTYL2w

### MIS-515 Homework 5: Online Review Classification
"""

"""
* MIS-515 : Assignment 5

* Problem Statement: create a tool that trains several machine learning models to perform the task of classifying online reviews. Some of 
these online reviews refer to hazardous products, so these machine learning models will help to identify the most serious product complaints.

The dataset is available at https://dgoldberg.sdsu.edu/515/appliance_reviews.json as a JSON array and contains approximately 1,000 reviews, 
approximately half of which refer to safety hazards.

The purpose of the machine learning models is to predict the “Safety hazard” field, which is already formatted as a 0 or 1. 
A value of 1 indicates that the review refers to a safety hazard; a value of 0 indicates that the review does not refer to a safety hazard. 

However, to transform the reviews into a format usable by the machine learning models, use the following four variables:
• Length: the number of characters in the review.
• Stars: the star rating assigned to the review.
• Polarity: the positive or negative emotive content in the review.
• Subjectivity: the opinionated or factual content in the review.

Train decision tree, k-nearest neighbors, and neural network machine learning models. You may choose an appropriate training/test split. 
Report the accuracy values from all three machine learning models and save a joblib file from the most accurate model. 
The printout of your code may be brief. For example:

Decision tree accuracy: 0.81
k-nearest neighbors accuracy: 0.74
Neural network accuracy: 0.86
Neural network model performed best; saved to model.joblib.
"""

# Homework - 5 : Solution
# Code Indent used : 4


# Importing the required libraries and installations
import nltk, textblob, json, requests, matplotlib.pyplot as plt, joblib, google.colab.files
nltk.download("punkt", quiet=True)

import sklearn
from sklearn import metrics, model_selection, tree, neighbors, neural_network

import warnings
warnings.filterwarnings("ignore")

# Welcome message to user
print("\n*** Welcome to the Online Review Classification - Training ML Model! ***\n")

# JSON Data URL
response = requests.get("https://dgoldberg.sdsu.edu/515/appliance_reviews.json")

# JSON Connection Successful (Status code 200)
if response:

    # JSON parser
    data = json.loads(response.text)
    # print(json.dumps(data, indent=4))

    # Initializing lists for responses and predictors
    x = []
    y = []

    # Parsing data for responses and predictors
    for line in data:
        
        # Feature names (Responses)
        review = line["Review"]
        stars = line["Stars"]
        
        # Calculate 'Length' feature
        length = len(review)

        # Calculate 'polarity' and 'subjectivity' features using textblob
        blob = textblob.TextBlob(line["Review"])
        polarity = blob.polarity
        subjectivity = blob.subjectivity

        # Class names (Predictors)
        safety_hazard = line["Safety hazard"]

        # Creating 2D Array for Responses(x) and 1D Array for Predictors(y)
        inner_list = [length, stars, polarity, subjectivity]
        x.append(inner_list)

        y.append(safety_hazard)

    # For printing the 2D array in matrix format
    # for row in x:
        # print(row)

    # print(y)

    # Break data into training and test portions
    x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, test_size = 0.25, random_state = 0)

    # Build Decision tree
    dt_clf = sklearn.tree.DecisionTreeClassifier()
    dt_clf = dt_clf.fit(x_train, y_train)

    # Decision tree Accuracy
    dt_predictions = dt_clf.predict(x_test)
    dt_accuracy = sklearn.metrics.accuracy_score(y_test, dt_predictions)
    print("Decision tree accuracy:", dt_accuracy)
    

    # Build KNN
    # Rule of thumb for 'k' value: find the square root of your sample size, then choose the nearest odd number.
    # Our sample size = 1000. Square Root (1000) = 31 (approximate)
    knn_clf = sklearn.neighbors.KNeighborsClassifier(31)
    knn_clf = knn_clf.fit(x_train, y_train)

    # KNN Accuracy
    knn_predictions = knn_clf.predict(x_test)
    knn_accuracy = sklearn.metrics.accuracy_score(y_test, knn_predictions)
    print("k-nearest neighbors accuracy:", knn_accuracy)


    # Build NN
    nn_clf = sklearn.neural_network.MLPClassifier()
    nn_clf = nn_clf.fit(x_train, y_train)

    # NN Accuracy
    nn_predictions = nn_clf.predict(x_test)
    nn_accuracy = sklearn.metrics.accuracy_score(y_test, nn_predictions)
    print("Neural network accuracy:", nn_accuracy)

    
    # Saving a joblib file from the most accurate model.
    # I have find out the MAXIMUM value of Accuracy between all models here.
    # Model having highest accuracy gets saved using joblib
    best_model = max(dt_accuracy, knn_accuracy, nn_accuracy)
    print("\nHightest Accuracy Model is: ", best_model)

    
    if best_model == dt_accuracy:
        joblib.dump(dt_clf, "model.joblib")
        google.colab.files.download("model.joblib")
        print("\nDecision tree model performed best; saved to model.joblib.\n")

    elif best_model == knn_accuracy:
        joblib.dump(knn_clf, "model.joblib")
        google.colab.files.download("model.joblib")
        print("\nk-nearest neighbors model performed best; saved to model.joblib.\n")

    elif best_model == nn_accuracy:
        joblib.dump(nn_clf, "model.joblib")
        google.colab.files.download("model.joblib")
        print("\nNeural network model performed best; saved to model.joblib.\n")

    else:
        print("Sorry, unable to determine the best performing ML model. Please execute the models again.")


# JSON Connection Error (Status code other than 200)
else:
    print("Sorry, connection error.")

# Exit message to user for Part-I
print("\n*** Thank you for using the Online Review Classification - Training ML Model. ***")